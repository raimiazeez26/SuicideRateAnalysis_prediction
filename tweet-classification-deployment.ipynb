{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Tweet Classification Deployment","metadata":{}},{"cell_type":"markdown","source":"## Import Libraries","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-15T20:17:54.438536Z","iopub.execute_input":"2021-11-15T20:17:54.438918Z","iopub.status.idle":"2021-11-15T20:17:54.45294Z","shell.execute_reply.started":"2021-11-15T20:17:54.438814Z","shell.execute_reply":"2021-11-15T20:17:54.452159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install tweepy","metadata":{"execution":{"iopub.status.busy":"2021-11-15T20:17:54.454681Z","iopub.execute_input":"2021-11-15T20:17:54.455171Z","iopub.status.idle":"2021-11-15T20:18:01.602274Z","shell.execute_reply.started":"2021-11-15T20:17:54.45508Z","shell.execute_reply":"2021-11-15T20:18:01.601144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\nimport string\n\nfrom sklearn.base import TransformerMixin, BaseEstimator\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.calibration import CalibratedClassifierCV\nfrom imblearn.under_sampling import InstanceHardnessThreshold\nfrom sklearn.svm import LinearSVC\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.linear_model import LogisticRegression, SGDClassifier\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.naive_bayes import MultinomialNB, ComplementNB\nfrom sklearn.svm import LinearSVC\n\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.utils.multiclass import unique_labels\nfrom sklearn.feature_selection import SelectFromModel\n\nimport tweepy\nfrom tweepy import OAuthHandler\nfrom textblob import TextBlob\nimport joblib\nfrom joblib import load\nfrom sklearn.base import TransformerMixin, BaseEstimator\n\nfrom imblearn.pipeline import Pipeline\nimport pickle\n\n#pd.set_option('display.max_colwidth', 1000)\n\nimport spacy\nnlp = spacy.load(\"en_core_web_lg\")\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2021-11-15T20:18:01.604245Z","iopub.execute_input":"2021-11-15T20:18:01.605011Z","iopub.status.idle":"2021-11-15T20:18:03.864666Z","shell.execute_reply.started":"2021-11-15T20:18:01.604962Z","shell.execute_reply":"2021-11-15T20:18:03.864003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load Pipeline","metadata":{}},{"cell_type":"code","source":"# Text Proccessing\n\nclass TextPreprocessor(BaseEstimator, TransformerMixin):\n    def __init__(self, text_attribute):\n        self.text_attribute = text_attribute\n    \n    def fit(self, X, y=None):\n        return self\n        \n    def transform(self, X, *_):\n        X_copy = X.copy()\n        return X_copy[self.text_attribute].apply(self._preprocess_text)\n    \n    def _preprocess_text(self, text):\n        return self._lemmatize(self._leave_letters_only(self._clean(text)))\n    \n    def _clean(self, text):\n        bad_symbols = '!\"#%&\\'*+,-<=>?[\\\\]^_`{|}~'\n        text_without_symbols = text.translate(str.maketrans('', '', bad_symbols))\n\n        text_without_bad_words = ''\n        for line in text_without_symbols.split('\\n'):\n            if not line.lower().startswith('from:') and not line.lower().endswith('writes:'):\n                text_without_bad_words += line + '\\n'\n\n        clean_text = text_without_bad_words\n        email_regex = r'([a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+)'\n        regexes_to_remove = [email_regex, r'Subject:', r'Re:']\n        for r in regexes_to_remove:\n            clean_text = re.sub(r, '', clean_text)\n\n        return clean_text\n    \n    def _leave_letters_only(self, text):\n        text_without_punctuation = text.translate(str.maketrans('', '', string.punctuation))\n        return ' '.join(re.findall(\"[a-zA-Z]+\", text_without_punctuation))\n    \n    def _lemmatize(self, text):\n        doc = nlp(text)\n        words = [x.lemma_ for x in [y for y in doc if not y.is_stop and y.pos_ != 'PUNCT' \n                                    and y.pos_ != 'PART' and y.pos_ != 'X']]\n        return ' '.join(words)\n    \n\nclass DenseTransformer(TransformerMixin):\n\n    def fit(self, X, y=None, **fit_params):\n        return self\n\n    def transform(self, X, y=None, **fit_params):\n        return X.todense()","metadata":{"execution":{"iopub.status.busy":"2021-11-15T20:18:03.871009Z","iopub.execute_input":"2021-11-15T20:18:03.871392Z","iopub.status.idle":"2021-11-15T20:18:03.885745Z","shell.execute_reply.started":"2021-11-15T20:18:03.871364Z","shell.execute_reply":"2021-11-15T20:18:03.884932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load the saved pipleine model\npipeline = load(\"../input/suicide-text-pipeline2/Suicide_text_classification (1).joblib\")","metadata":{"execution":{"iopub.status.busy":"2021-11-15T20:18:03.88683Z","iopub.execute_input":"2021-11-15T20:18:03.88704Z","iopub.status.idle":"2021-11-15T20:18:04.053836Z","shell.execute_reply.started":"2021-11-15T20:18:03.887016Z","shell.execute_reply":"2021-11-15T20:18:04.052972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Twitter client for connecting to Twitter, fetch tweets and get sentiment\n\nclass TwitterClient(object):\n    '''\n    Generic Twitter Class for sentiment analysis.\n    '''\n    def __init__(self):\n        '''\n        Class constructor or initialization method.\n        '''\n        # keys and tokens from the Twitter Dev Console\n        consumer_key = ''\n        consumer_secret = ''\n        access_token = ''\n        access_token_secret = ''\n        \n        # attempt authentication\n        try:\n            # create OAuthHandler object\n            self.auth = OAuthHandler(consumer_key, consumer_secret)\n            # set access token and secret\n            self.auth.set_access_token(access_token, access_token_secret)\n            # create tweepy API object to fetch tweets\n            self.api = tweepy.API(self.auth)\n            self.api.verify_credentials()\n            print(\"Authentication OK!\")\n        except:\n            print(\"Error: Authentication Failed\")\n\n    def clean_tweet(self, tweet):\n        '''\n        Utility function to clean tweet text by removing links, special characters\n        using simple regex statements.\n        '''\n        return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet).split())\n\n    def get_tweet_sentiment(self, tweet):\n        '''\n        Utility function to classify sentiment of passed tweet\n        using textblob's sentiment method\n        '''\n        # create TextBlob object of passed tweet text\n        analysis = TextBlob(self.clean_tweet(tweet))\n        # set sentiment\n        if analysis.sentiment.polarity > 0:\n            return 'positive'\n        elif analysis.sentiment.polarity == 0:\n            return 'neutral'\n        else:\n            return 'negative'\n\n    def get_tweets(self, query, count, lang, locale):\n        '''\n        Main function to fetch tweets and parse them.\n        '''\n        # empty list to store parsed tweets\n        tweets = []\n\n        try:\n            # call twitter api to fetch tweets\n            fetched_tweets = self.api.search_tweets(q = query, count = count, lang = lang, locale = locale)\n\n            # parsing tweets one by one\n            for tweet in fetched_tweets:\n                # empty dictionary to store required params of a tweet\n                parsed_tweet = {}\n\n                # saving text of tweet\n                parsed_tweet['text'] = tweet.text\n                # saving sentiment of tweet\n                parsed_tweet['sentiment'] = self.get_tweet_sentiment(tweet.text)\n\n                # appending parsed tweet to tweets list\n                if tweet.retweet_count > 0:\n                    # if tweet has retweets, ensure that it is appended only once\n                    if parsed_tweet not in tweets:\n                        tweets.append(parsed_tweet)\n                else:\n                    tweets.append(parsed_tweet)\n\n            # return parsed tweets\n            return tweets\n\n        except tweepy.TweepError as e:\n            # print error (if any)\n            print(\"Error : \" + str(e))\n","metadata":{"execution":{"iopub.status.busy":"2021-11-15T20:18:04.055495Z","iopub.execute_input":"2021-11-15T20:18:04.055825Z","iopub.status.idle":"2021-11-15T20:18:04.06728Z","shell.execute_reply.started":"2021-11-15T20:18:04.055763Z","shell.execute_reply":"2021-11-15T20:18:04.066359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Get Tweet & Predict","metadata":{}},{"cell_type":"code","source":"import json\nimport plotly\nimport plotly.express as px\n\ndef main(q):\n    # creating object of TwitterClient Class\n    api = TwitterClient()\n    # calling function to get tweets\n    global tweets, tweets_df, graphJSON\n    #q = input(\"Enter text to predict :\")\n    tweets = api.get_tweets(query = q, count = 200, lang = \"en\", locale = \"ja\")\n    \n    tweets_df = pd.DataFrame(tweets)\n    tweets_text = tweets_df.drop(columns = [\"sentiment\"])\n    \n    pred = pipeline.predict(tweets_text)\n    \n    tweets_df[\"prediction\"] = pred\n    \n    #pie chart of world suicide rate by sex 1985-2016\n\n    data = tweets_df.prediction.value_counts()\n    labels = [\"non-suicide\", \"suicide\"]\n    colors = sns.color_palette('pastel')[0:5]\n    \n\n    fig = px.pie(data, values = data, names= labels)\n    #fig.show()\n    graphJSON = json.dumps(fig, cls=plotly.utils.PlotlyJSONEncoder)\n    \n    #print(tweets_df)\n    return tweets_df\n\n    \n\n#if __name__ == \"__main__\":\n    # calling main function\n    #main()\n","metadata":{"execution":{"iopub.status.busy":"2021-11-15T20:18:04.068352Z","iopub.execute_input":"2021-11-15T20:18:04.068865Z","iopub.status.idle":"2021-11-15T20:18:04.082914Z","shell.execute_reply.started":"2021-11-15T20:18:04.068831Z","shell.execute_reply":"2021-11-15T20:18:04.081963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Deploy Using Flask","metadata":{}},{"cell_type":"code","source":"#pip freeze > requirements.txt","metadata":{"execution":{"iopub.status.busy":"2021-11-15T20:18:04.08553Z","iopub.execute_input":"2021-11-15T20:18:04.085747Z","iopub.status.idle":"2021-11-15T20:18:04.098651Z","shell.execute_reply.started":"2021-11-15T20:18:04.085722Z","shell.execute_reply":"2021-11-15T20:18:04.097491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install flask","metadata":{"execution":{"iopub.status.busy":"2021-11-15T20:18:04.100538Z","iopub.execute_input":"2021-11-15T20:18:04.10081Z","iopub.status.idle":"2021-11-15T20:18:11.477301Z","shell.execute_reply.started":"2021-11-15T20:18:04.10075Z","shell.execute_reply":"2021-11-15T20:18:11.476249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install flask-ngrok","metadata":{"execution":{"iopub.status.busy":"2021-11-15T20:18:11.479204Z","iopub.execute_input":"2021-11-15T20:18:11.479451Z","iopub.status.idle":"2021-11-15T20:18:18.937327Z","shell.execute_reply.started":"2021-11-15T20:18:11.47942Z","shell.execute_reply":"2021-11-15T20:18:18.93626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! pip install pyngrok","metadata":{"execution":{"iopub.status.busy":"2021-11-15T20:18:18.93895Z","iopub.execute_input":"2021-11-15T20:18:18.939232Z","iopub.status.idle":"2021-11-15T20:18:26.255398Z","shell.execute_reply.started":"2021-11-15T20:18:18.939199Z","shell.execute_reply":"2021-11-15T20:18:26.254373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#importing the required libraries\nfrom flask import Flask, render_template, request, redirect, url_for\nfrom joblib import load\nfrom flask_ngrok import run_with_ngrok\n#from get_tweets import get_related_tweets\nfrom logging import FileHandler,WARNING","metadata":{"execution":{"iopub.status.busy":"2021-11-15T20:18:26.256984Z","iopub.execute_input":"2021-11-15T20:18:26.25726Z","iopub.status.idle":"2021-11-15T20:18:26.261555Z","shell.execute_reply.started":"2021-11-15T20:18:26.257227Z","shell.execute_reply":"2021-11-15T20:18:26.26101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! ngrok authtoken auth_key","metadata":{"execution":{"iopub.status.busy":"2021-11-15T20:18:26.262649Z","iopub.execute_input":"2021-11-15T20:18:26.26289Z","iopub.status.idle":"2021-11-15T20:18:27.253537Z","shell.execute_reply.started":"2021-11-15T20:18:26.262863Z","shell.execute_reply":"2021-11-15T20:18:27.252761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport threading\n\nfrom flask import Flask\nfrom pyngrok import ngrok\n\n# Open a HTTP tunnel on the default port 80\npublic_url = ngrok.connect(port = '4040')\n\nos.environ[\"FLASK_ENV\"] = \"development\"\n\napp = Flask(__name__, template_folder = \"../input/templates\")\nport = 5000\n\n# Open a ngrok tunnel to the HTTP server\npublic_url = ngrok.connect(port).public_url\nprint(\" * ngrok tunnel \\\"{}\\\" -> \\\"http://127.0.0.1:{}\\\"\".format(public_url, port))\n\n# Update any base URLs to use the public ngrok URL\napp.config[\"BASE_URL\"] = public_url\n\n# ... Update inbound traffic via APIs to use the public-facing ngrok URL\n\n\n# Define Flask routes\n# render default webpage\n@app.route('/')\ndef home():\n    return render_template('index.html')\n\n# when the post method detect, then redirect to success function\n@app.route('/', methods=['POST', 'GET'])\ndef get_data():\n    if request.method == 'POST':\n        user = request.form['text']\n        return redirect(url_for('success', name=user))\n\n# get the data for the requested query\n@app.route('/success/<name>')\ndef success(name):\n    results = main(name)\n    \n    return render_template('simple.html', tables=[results.to_html(classes='data')], titles= results.columns.values, graphJSON=graphJSON)\n\n","metadata":{"execution":{"iopub.status.busy":"2021-11-15T20:19:19.744367Z","iopub.execute_input":"2021-11-15T20:19:19.744629Z","iopub.status.idle":"2021-11-15T20:19:20.695927Z","shell.execute_reply.started":"2021-11-15T20:19:19.744603Z","shell.execute_reply":"2021-11-15T20:19:20.69513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Start the Flask server in a new thread\nthreading.Thread(target=app.run, kwargs={\"use_reloader\": False}).start()","metadata":{"execution":{"iopub.status.busy":"2021-11-15T20:19:31.625873Z","iopub.execute_input":"2021-11-15T20:19:31.626712Z","iopub.status.idle":"2021-11-15T20:19:31.636498Z","shell.execute_reply.started":"2021-11-15T20:19:31.626662Z","shell.execute_reply":"2021-11-15T20:19:31.635208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"#ngrok.kill()","metadata":{"execution":{"iopub.status.busy":"2021-11-15T20:22:58.980821Z","iopub.execute_input":"2021-11-15T20:22:58.981529Z","iopub.status.idle":"2021-11-15T20:22:58.988054Z","shell.execute_reply.started":"2021-11-15T20:22:58.981488Z","shell.execute_reply":"2021-11-15T20:22:58.987442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}