{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Tweet Classification Deployment","metadata":{}},{"cell_type":"markdown","source":"## Import Libraries","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-15T12:23:26.033256Z","iopub.execute_input":"2021-11-15T12:23:26.034004Z","iopub.status.idle":"2021-11-15T12:23:26.046055Z","shell.execute_reply.started":"2021-11-15T12:23:26.033954Z","shell.execute_reply":"2021-11-15T12:23:26.045157Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"pip install tweepy","metadata":{"execution":{"iopub.status.busy":"2021-11-15T12:23:26.119952Z","iopub.execute_input":"2021-11-15T12:23:26.120752Z","iopub.status.idle":"2021-11-15T12:23:33.376818Z","shell.execute_reply.started":"2021-11-15T12:23:26.120702Z","shell.execute_reply":"2021-11-15T12:23:33.375769Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import re\nimport string\n\nfrom sklearn.base import TransformerMixin, BaseEstimator\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.calibration import CalibratedClassifierCV\nfrom imblearn.under_sampling import InstanceHardnessThreshold\nfrom sklearn.svm import LinearSVC\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.linear_model import LogisticRegression, SGDClassifier\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.naive_bayes import MultinomialNB, ComplementNB\nfrom sklearn.svm import LinearSVC\n\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.utils.multiclass import unique_labels\nfrom sklearn.feature_selection import SelectFromModel\n\nimport tweepy\nfrom tweepy import OAuthHandler\nfrom textblob import TextBlob\nimport joblib\nfrom joblib import load\nfrom sklearn.base import TransformerMixin, BaseEstimator\n\nfrom imblearn.pipeline import Pipeline\nimport pickle\n\n#pd.set_option('display.max_colwidth', 1000)\n\nimport spacy\nnlp = spacy.load(\"en_core_web_lg\")\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2021-11-15T12:24:12.992935Z","iopub.execute_input":"2021-11-15T12:24:12.993247Z","iopub.status.idle":"2021-11-15T12:24:19.295725Z","shell.execute_reply.started":"2021-11-15T12:24:12.993204Z","shell.execute_reply":"2021-11-15T12:24:19.294739Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"#pd.set_option('display.max_colwidth', None)\n#pd.set_option(\"max_columns\", None)\n#pd.set_option('max_colwidth', None)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load Pipeline","metadata":{}},{"cell_type":"code","source":"# Text Proccessing\n\nclass TextPreprocessor(BaseEstimator, TransformerMixin):\n    def __init__(self, text_attribute):\n        self.text_attribute = text_attribute\n    \n    def fit(self, X, y=None):\n        return self\n        \n    def transform(self, X, *_):\n        X_copy = X.copy()\n        return X_copy[self.text_attribute].apply(self._preprocess_text)\n    \n    def _preprocess_text(self, text):\n        return self._lemmatize(self._leave_letters_only(self._clean(text)))\n    \n    def _clean(self, text):\n        bad_symbols = '!\"#%&\\'*+,-<=>?[\\\\]^_`{|}~'\n        text_without_symbols = text.translate(str.maketrans('', '', bad_symbols))\n\n        text_without_bad_words = ''\n        for line in text_without_symbols.split('\\n'):\n            if not line.lower().startswith('from:') and not line.lower().endswith('writes:'):\n                text_without_bad_words += line + '\\n'\n\n        clean_text = text_without_bad_words\n        email_regex = r'([a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+)'\n        regexes_to_remove = [email_regex, r'Subject:', r'Re:']\n        for r in regexes_to_remove:\n            clean_text = re.sub(r, '', clean_text)\n\n        return clean_text\n    \n    def _leave_letters_only(self, text):\n        text_without_punctuation = text.translate(str.maketrans('', '', string.punctuation))\n        return ' '.join(re.findall(\"[a-zA-Z]+\", text_without_punctuation))\n    \n    def _lemmatize(self, text):\n        doc = nlp(text)\n        words = [x.lemma_ for x in [y for y in doc if not y.is_stop and y.pos_ != 'PUNCT' \n                                    and y.pos_ != 'PART' and y.pos_ != 'X']]\n        return ' '.join(words)\n    \n\nclass DenseTransformer(TransformerMixin):\n\n    def fit(self, X, y=None, **fit_params):\n        return self\n\n    def transform(self, X, y=None, **fit_params):\n        return X.todense()","metadata":{"execution":{"iopub.status.busy":"2021-11-15T12:24:19.297461Z","iopub.execute_input":"2021-11-15T12:24:19.297775Z","iopub.status.idle":"2021-11-15T12:24:19.312266Z","shell.execute_reply.started":"2021-11-15T12:24:19.297740Z","shell.execute_reply":"2021-11-15T12:24:19.311434Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# load the saved pipleine model\npipeline = load(\"../input/suicide-text-pipeline2/Suicide_text_classification (1).joblib\")","metadata":{"execution":{"iopub.status.busy":"2021-11-15T12:24:19.313725Z","iopub.execute_input":"2021-11-15T12:24:19.313972Z","iopub.status.idle":"2021-11-15T12:24:19.470305Z","shell.execute_reply.started":"2021-11-15T12:24:19.313945Z","shell.execute_reply":"2021-11-15T12:24:19.469490Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"#Twitter client for connecting to Twitter, fetch tweets and get sentiment\n\nclass TwitterClient(object):\n    '''\n    Generic Twitter Class for sentiment analysis.\n    '''\n    def __init__(self):\n        '''\n        Class constructor or initialization method.\n        '''\n        # keys and tokens from the Twitter Dev Console\n        consumer_key = 'xeBnocCW5BUdWkf8nxV4yCdmq'\n        consumer_secret = 'r0IwBH4VV0F8AH7GGXfJ6FueWt5Cc1VstEzcKyVH2Rhn4mBJZj'\n        access_token = '336239701-ELhAtnZciTmNwDrkYAlv3EmS58xfjpWY6JAKD7ik'\n        access_token_secret = 'iaVZc0rZaDSBQonLXpiwnGD3KLPXk1OVf3Q50YHYJlV8x'\n        \n        # attempt authentication\n        try:\n            # create OAuthHandler object\n            self.auth = OAuthHandler(consumer_key, consumer_secret)\n            # set access token and secret\n            self.auth.set_access_token(access_token, access_token_secret)\n            # create tweepy API object to fetch tweets\n            self.api = tweepy.API(self.auth)\n            self.api.verify_credentials()\n            print(\"Authentication OK!\")\n        except:\n            print(\"Error: Authentication Failed\")\n\n    def clean_tweet(self, tweet):\n        '''\n        Utility function to clean tweet text by removing links, special characters\n        using simple regex statements.\n        '''\n        return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet).split())\n\n    def get_tweet_sentiment(self, tweet):\n        '''\n        Utility function to classify sentiment of passed tweet\n        using textblob's sentiment method\n        '''\n        # create TextBlob object of passed tweet text\n        analysis = TextBlob(self.clean_tweet(tweet))\n        # set sentiment\n        if analysis.sentiment.polarity > 0:\n            return 'positive'\n        elif analysis.sentiment.polarity == 0:\n            return 'neutral'\n        else:\n            return 'negative'\n\n    def get_tweets(self, query, count, lang, locale):\n        '''\n        Main function to fetch tweets and parse them.\n        '''\n        # empty list to store parsed tweets\n        tweets = []\n\n        try:\n            # call twitter api to fetch tweets\n            fetched_tweets = self.api.search_tweets(q = query, count = count, lang = lang, locale = locale)\n\n            # parsing tweets one by one\n            for tweet in fetched_tweets:\n                # empty dictionary to store required params of a tweet\n                parsed_tweet = {}\n\n                # saving text of tweet\n                parsed_tweet['text'] = tweet.text\n                # saving sentiment of tweet\n                parsed_tweet['sentiment'] = self.get_tweet_sentiment(tweet.text)\n\n                # appending parsed tweet to tweets list\n                if tweet.retweet_count > 0:\n                    # if tweet has retweets, ensure that it is appended only once\n                    if parsed_tweet not in tweets:\n                        tweets.append(parsed_tweet)\n                else:\n                    tweets.append(parsed_tweet)\n\n            # return parsed tweets\n            return tweets\n\n        except tweepy.TweepError as e:\n            # print error (if any)\n            print(\"Error : \" + str(e))\n","metadata":{"execution":{"iopub.status.busy":"2021-11-15T12:24:19.471795Z","iopub.execute_input":"2021-11-15T12:24:19.472021Z","iopub.status.idle":"2021-11-15T12:24:19.483175Z","shell.execute_reply.started":"2021-11-15T12:24:19.471992Z","shell.execute_reply":"2021-11-15T12:24:19.482311Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## Get Tweet & Predict","metadata":{}},{"cell_type":"code","source":"import json\nimport plotly\nimport plotly.express as px\n\ndef main(q):\n    # creating object of TwitterClient Class\n    api = TwitterClient()\n    # calling function to get tweets\n    global tweets, tweets_df, graphJSON\n    #q = input(\"Enter text to predict :\")\n    tweets = api.get_tweets(query = q, count = 200, lang = \"en\", locale = \"ja\")\n    \n    tweets_df = pd.DataFrame(tweets)\n    tweets_text = tweets_df.drop(columns = [\"sentiment\"])\n    \n    pred = pipeline.predict(tweets_text)\n    \n    tweets_df[\"prediction\"] = pred\n    \n    #pie chart of world suicide rate by sex 1985-2016\n\n    data = tweets_df.prediction.value_counts()\n    labels = [\"non-suicide\", \"suicide\"]\n    colors = sns.color_palette('pastel')[0:5]\n    \n\n    fig = px.pie(data, values = data, names= labels)\n    #fig.show()\n    graphJSON = json.dumps(fig, cls=plotly.utils.PlotlyJSONEncoder)\n    \n    #print(tweets_df)\n    return tweets_df\n\n    \n\n#if __name__ == \"__main__\":\n    # calling main function\n    #main()\n","metadata":{"execution":{"iopub.status.busy":"2021-11-15T12:24:34.690231Z","iopub.execute_input":"2021-11-15T12:24:34.690586Z","iopub.status.idle":"2021-11-15T12:24:35.252546Z","shell.execute_reply.started":"2021-11-15T12:24:34.690547Z","shell.execute_reply":"2021-11-15T12:24:35.251451Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Deploy Using Flask","metadata":{}},{"cell_type":"code","source":"#pip freeze > requirements.txt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install flask","metadata":{"execution":{"iopub.status.busy":"2021-11-15T12:24:40.168064Z","iopub.execute_input":"2021-11-15T12:24:40.168383Z","iopub.status.idle":"2021-11-15T12:24:47.464319Z","shell.execute_reply.started":"2021-11-15T12:24:40.168334Z","shell.execute_reply":"2021-11-15T12:24:47.463456Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"!pip install flask-ngrok","metadata":{"execution":{"iopub.status.busy":"2021-11-15T12:24:47.466525Z","iopub.execute_input":"2021-11-15T12:24:47.466803Z","iopub.status.idle":"2021-11-15T12:24:54.685279Z","shell.execute_reply.started":"2021-11-15T12:24:47.466774Z","shell.execute_reply":"2021-11-15T12:24:54.684470Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"! pip install pyngrok","metadata":{"execution":{"iopub.status.busy":"2021-11-15T12:24:54.686690Z","iopub.execute_input":"2021-11-15T12:24:54.686953Z","iopub.status.idle":"2021-11-15T12:25:02.004351Z","shell.execute_reply.started":"2021-11-15T12:24:54.686916Z","shell.execute_reply":"2021-11-15T12:25:02.003137Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"#importing the required libraries\nfrom flask import Flask, render_template, request, redirect, url_for\nfrom joblib import load\nfrom flask_ngrok import run_with_ngrok\n#from get_tweets import get_related_tweets\nfrom logging import FileHandler,WARNING","metadata":{"execution":{"iopub.status.busy":"2021-11-15T12:25:11.660465Z","iopub.execute_input":"2021-11-15T12:25:11.661226Z","iopub.status.idle":"2021-11-15T12:25:11.742771Z","shell.execute_reply.started":"2021-11-15T12:25:11.661172Z","shell.execute_reply":"2021-11-15T12:25:11.741774Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"! ngrok authtoken 20x5v7xjlqWfhYPLBEtGvaen1co_6DTY5UgHZszoT42gJrCxT","metadata":{"execution":{"iopub.status.busy":"2021-11-15T12:25:11.905985Z","iopub.execute_input":"2021-11-15T12:25:11.906296Z","iopub.status.idle":"2021-11-15T12:25:12.886449Z","shell.execute_reply.started":"2021-11-15T12:25:11.906262Z","shell.execute_reply":"2021-11-15T12:25:12.885412Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"import os\nimport threading\n\nfrom flask import Flask\nfrom pyngrok import ngrok\n\n# Open a HTTP tunnel on the default port 80\npublic_url = ngrok.connect(port = '4040')\n\nos.environ[\"FLASK_ENV\"] = \"development\"\n\napp = Flask(__name__, template_folder = \"../input/templates\")\nport = 5000\n\n# Open a ngrok tunnel to the HTTP server\npublic_url = ngrok.connect(port).public_url\nprint(\" * ngrok tunnel \\\"{}\\\" -> \\\"http://127.0.0.1:{}\\\"\".format(public_url, port))\n\n# Update any base URLs to use the public ngrok URL\napp.config[\"BASE_URL\"] = public_url\n\n# ... Update inbound traffic via APIs to use the public-facing ngrok URL\n\n\n# Define Flask routes\n# render default webpage\n@app.route('/')\ndef home():\n    return render_template('index.html')\n\n# when the post method detect, then redirect to success function\n@app.route('/', methods=['POST', 'GET'])\ndef get_data():\n    if request.method == 'POST':\n        user = request.form['text']\n        return redirect(url_for('success', name=user))\n\n# get the data for the requested query\n@app.route('/success/<name>')\ndef success(name):\n    results = main(name)\n    \n    return render_template('simple.html', tables=[results.to_html(classes='data')], titles= results.columns.values, graphJSON=graphJSON)\n\n","metadata":{"execution":{"iopub.status.busy":"2021-11-15T12:25:41.293914Z","iopub.execute_input":"2021-11-15T12:25:41.294204Z","iopub.status.idle":"2021-11-15T12:25:42.914035Z","shell.execute_reply.started":"2021-11-15T12:25:41.294176Z","shell.execute_reply":"2021-11-15T12:25:42.912652Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# Start the Flask server in a new thread\n#threading.Thread(target=app.run, kwargs={\"use_reloader\": False}).start()","metadata":{"execution":{"iopub.status.busy":"2021-11-15T12:25:48.776454Z","iopub.execute_input":"2021-11-15T12:25:48.777300Z","iopub.status.idle":"2021-11-15T12:25:48.790867Z","shell.execute_reply.started":"2021-11-15T12:25:48.777254Z","shell.execute_reply":"2021-11-15T12:25:48.785571Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"\"\"\"#set display option\npd.set_option('display.max_rows', 200)\n# start flask\napp = Flask(__name__, template_folder = \"../input/templates\")\nrun_with_ngrok(app)\n#app.debug = True\n\n# render default webpage\n@app.route('/')\ndef home():\n    return render_template('index.html')\n\n# when the post method detect, then redirect to success function\n@app.route('/', methods=['POST', 'GET'])\ndef get_data():\n    if request.method == 'POST':\n        user = request.form['text']\n        return redirect(url_for('success', name=user))\n\n# get the data for the requested query\n@app.route('/success/<name>')\ndef success(name):\n    results = main(name)\n    \n    return render_template('simple.html', tables=[results.to_html(classes='data')], titles= results.columns.values, graphJSON=graphJSON)\n#\"<xmp>\" + str(main(name)) + \" </xmp> \"\nif __name__ == '__main__':\n    app.run() \"\"\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"ngrok.kill()","metadata":{"execution":{"iopub.status.busy":"2021-11-15T12:36:21.731301Z","iopub.execute_input":"2021-11-15T12:36:21.731808Z","iopub.status.idle":"2021-11-15T12:36:21.735263Z","shell.execute_reply.started":"2021-11-15T12:36:21.731757Z","shell.execute_reply":"2021-11-15T12:36:21.734583Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}